{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from missforest import MissForest\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 2*10**4\n",
    "d = 10\n",
    "\n",
    "lr = 0.01\n",
    "epochs = 60\n",
    "l1_lambda = 0\n",
    "\n",
    "X = np.random.uniform(0, 1, (n, d))\n",
    "epsilon = np.random.normal(0, 0.25, n)\n",
    "Y = np.zeros(n)\n",
    "probs = np.zeros(n)\n",
    "\n",
    "def reg_func(x):\n",
    "    out = np.exp(10*x[1]**2) / (np.exp(10*x[1]**2) + np.exp(10*x[2]*x[3] + 2*x[3]))   \n",
    "    return out\n",
    "for i in range(n):\n",
    "    probs[i] = reg_func(X[i,:])\n",
    "    Y[i] = np.random.binomial(1, probs[i], 1)[0]\n",
    "\n",
    "Omega = np.random.binomial(1, 0.5, (n, d))\n",
    "for i in range(n):\n",
    "    if probs[i] <= 0.6:\n",
    "        Omega[i,1] = 0\n",
    "    else:\n",
    "        Omega[i,1] = 1\n",
    "sample_mean = np.sum(X*Omega, axis = 0) / np.sum(Omega, axis = 0)\n",
    "Z_ZI = X * Omega\n",
    "Z_MI = X * Omega + sample_mean * (1 - Omega)\n",
    "Z_RI = X * Omega + (1 - Omega) * np.random.uniform(0, 1, (n, d))\n",
    "\n",
    "\n",
    "Z_ZI_train = Z_ZI[0:int(n/2), :]\n",
    "Z_ZI_test = Z_ZI[int(n/2):n, :]\n",
    "Z_MI_train = Z_MI[0:int(n/2), :]\n",
    "Z_MI_test = Z_MI[int(n/2):n, :]\n",
    "Omega_train = Omega[0:int(n/2), :]\n",
    "Omega_test = Omega[int(n/2):n, :]\n",
    "\n",
    "Y_train = Y[0:int(n/2)]\n",
    "Y_test = Y[int(n/2):n]\n",
    "\n",
    "Z_ZI_train = torch.tensor(Z_ZI_train, dtype=torch.float32)\n",
    "Z_ZI_test = torch.tensor(Z_ZI_test, dtype=torch.float32)\n",
    "Z_MI_train = torch.tensor(Z_MI_train, dtype=torch.float32)\n",
    "Z_MI_test = torch.tensor(Z_MI_test, dtype=torch.float32)\n",
    "Omega_train = torch.tensor(Omega_train, dtype=torch.float32)\n",
    "Omega_test = torch.tensor(Omega_test, dtype=torch.float32)\n",
    "Z_Omega_train = torch.cat((Z_ZI_train, Omega_train), dim = 1)\n",
    "Z_Omega_test = torch.cat((Z_ZI_test, Omega_test), dim = 1)\n",
    "\n",
    "Y_train = torch.tensor(Y_train, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.13590952064185927)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([min(y, 1-y) for y in probs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Loss: 0.7774490714073181\n",
      "Epoch 19, Loss: 0.7479819059371948\n",
      "Epoch 29, Loss: 0.31456458568573\n",
      "Epoch 39, Loss: 0.34804767370224\n",
      "Epoch 49, Loss: 0.20058691501617432\n",
      "Epoch 59, Loss: 0.4071352779865265\n",
      "0.136\n"
     ]
    }
   ],
   "source": [
    "### pattern augmented NN\n",
    "class PANN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.arch1 = nn.Sequential(\n",
    "            nn.Linear(2*d, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 2),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.arch1(x)\n",
    "        return out\n",
    "    \n",
    "model_PA = PANN()\n",
    "PA_train_data = TensorDataset(Z_Omega_train, Y_train)\n",
    "PA_train_loader = DataLoader(dataset = PA_train_data, batch_size=20, shuffle=True)\n",
    "\n",
    "optimizer = optim.SGD(model_PA.parameters(), lr=lr)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    for x_batch, y_batch in PA_train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        pred = model_PA(x_batch)\n",
    "        loss = loss_fn(pred, y_batch)\n",
    "\n",
    "        # L1 penalty\n",
    "        l1_penalty = 0\n",
    "        for param in model_PA.parameters():\n",
    "            l1_penalty += torch.sum(torch.abs(param))\n",
    "        # Add L1 penalty to the loss\n",
    "        loss += l1_lambda * l1_penalty\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    if epoch % 10 == 9:\n",
    "        print(f'Epoch {epoch}, Loss: {loss.item()}')\n",
    "\n",
    "_, labels = torch.max(model_PA(Z_Omega_test), dim=1)\n",
    "pred = labels.detach().numpy()\n",
    "ER_PA = np.mean(np.abs(pred - Y_test))\n",
    "print(ER_PA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Loss: 0.683150053024292\n",
      "Epoch 19, Loss: 0.6804202198982239\n",
      "Epoch 29, Loss: 0.6860231161117554\n",
      "Epoch 39, Loss: 0.628186047077179\n",
      "Epoch 49, Loss: 0.7132441401481628\n",
      "Epoch 59, Loss: 0.4683532118797302\n",
      "0.3437\n"
     ]
    }
   ],
   "source": [
    "### mean imputation\n",
    "class MINN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.arch1 = nn.Sequential(\n",
    "            nn.Linear(d, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 2),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.arch1(x)\n",
    "        return out\n",
    "    \n",
    "model_MI = MINN()\n",
    "train_data = TensorDataset(Z_MI_train, Y_train)\n",
    "train_loader = DataLoader(dataset = train_data, batch_size=20, shuffle=True)\n",
    "\n",
    "optimizer = optim.SGD(model_MI.parameters(), lr=lr)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    for x_batch, y_batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        pred = model_MI(x_batch)\n",
    "        loss = loss_fn(pred, y_batch)\n",
    "\n",
    "        # L1 penalty\n",
    "        l1_penalty = 0\n",
    "        for param in model_MI.parameters():\n",
    "            l1_penalty += torch.sum(torch.abs(param))\n",
    "        # Add L1 penalty to the loss\n",
    "        loss += l1_lambda * l1_penalty\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    if epoch % 10 == 9:\n",
    "        print(f'Epoch {epoch}, Loss: {loss.item()}')\n",
    "\n",
    "\n",
    "_, labels = torch.max(model_MI(Z_MI_test), dim=1)\n",
    "pred = labels.detach().numpy()\n",
    "ER_MI = np.mean(np.abs(pred - Y_test))\n",
    "print(ER_MI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:05<00:00,  1.17s/it]\n",
      "100%|██████████| 5/5 [00:04<00:00,  1.21it/s]\n"
     ]
    }
   ],
   "source": [
    "### MissForest imputation\n",
    "Z_nan = np.copy(Z_ZI)\n",
    "for i in range(n):\n",
    "    for j in range(d):\n",
    "        if Omega[i, j] == 0:\n",
    "            Z_nan[i,j] = np.nan\n",
    "Z_nan_train = pd.DataFrame(Z_nan[0:int(n/2), :])\n",
    "Z_nan_test = pd.DataFrame(Z_nan[int(n/2):n, :])\n",
    "rgr = RandomForestRegressor(n_jobs=-1)\n",
    "warnings.filterwarnings('ignore')\n",
    "mf = MissForest(rgr)\n",
    "mf.fit(x=Z_nan_train)\n",
    "Z_MF_train = mf.transform(Z_nan_train)\n",
    "Z_MF_test = mf.transform(Z_nan_test)\n",
    "Z_MF_train = Z_MF_train.to_numpy()\n",
    "Z_MF_test = Z_MF_test.to_numpy()\n",
    "\n",
    "Z_MF_train = torch.tensor(Z_MF_train, dtype=torch.float32)\n",
    "Z_MF_test = torch.tensor(Z_MF_test, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Loss: 0.6236905455589294\n",
      "Epoch 19, Loss: 0.5519787073135376\n",
      "Epoch 29, Loss: 0.5759331583976746\n",
      "Epoch 39, Loss: 0.5725918412208557\n",
      "Epoch 49, Loss: 0.49116554856300354\n",
      "Epoch 59, Loss: 0.6833811402320862\n",
      "0.3028\n"
     ]
    }
   ],
   "source": [
    "### MissForest imputation\n",
    "class MFNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.arch1 = nn.Sequential(\n",
    "            nn.Linear(d, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 2),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.arch1(x)\n",
    "        return out\n",
    "    \n",
    "model_MF = MFNN()\n",
    "train_data = TensorDataset(Z_MF_train, Y_train)\n",
    "train_loader = DataLoader(dataset = train_data, batch_size=20, shuffle=True)\n",
    "\n",
    "optimizer = optim.SGD(model_MF.parameters(), lr=lr)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    for x_batch, y_batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        pred = model_MF(x_batch)\n",
    "        loss = loss_fn(pred, y_batch)\n",
    "\n",
    "        # L1 penalty\n",
    "        l1_penalty = 0\n",
    "        for param in model_MF.parameters():\n",
    "            l1_penalty += torch.sum(torch.abs(param))\n",
    "        # Add L1 penalty to the loss\n",
    "        loss += l1_lambda * l1_penalty\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    if epoch % 10 == 9:\n",
    "        print(f'Epoch {epoch}, Loss: {loss.item()}')\n",
    "\n",
    "_, labels = torch.max(model_MF(Z_MF_test), dim=1)\n",
    "pred = labels.detach().numpy()\n",
    "ER_MF = np.mean(np.abs(pred - Y_test))\n",
    "print(ER_MF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mttyy\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\impute\\_iterative.py:825: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "### MICE imputation\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "Z_nan = np.copy(Z_ZI)\n",
    "for i in range(n):\n",
    "    for j in range(d):\n",
    "        if Omega[i, j] == 0:\n",
    "            Z_nan[i,j] = np.nan\n",
    "Z_nan_train = pd.DataFrame(Z_nan[0:int(n/2), :])\n",
    "Z_nan_test = pd.DataFrame(Z_nan[int(n/2):n, :])\n",
    "\n",
    "imputer = IterativeImputer(max_iter=10, random_state=0)\n",
    "fitted_imputer = imputer.fit(Z_nan_train)\n",
    "Z_MICE_train = fitted_imputer.transform(Z_nan_train)\n",
    "Z_MICE_test = fitted_imputer.transform(Z_nan_test)\n",
    "Z_MICE_train = Z_MICE_train\n",
    "Z_MICE_test = Z_MICE_test\n",
    "\n",
    "Z_MICE_train = torch.tensor(Z_MICE_train, dtype=torch.float32)\n",
    "Z_MICE_test = torch.tensor(Z_MICE_test, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Loss: 0.695248007774353\n",
      "Epoch 19, Loss: 0.6834633946418762\n",
      "Epoch 29, Loss: 0.7101015448570251\n",
      "Epoch 39, Loss: 0.6057878732681274\n",
      "Epoch 49, Loss: 0.7067535519599915\n",
      "Epoch 59, Loss: 0.624566912651062\n",
      "0.3473\n"
     ]
    }
   ],
   "source": [
    "### MICE imputation\n",
    "class MICENN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.arch1 = nn.Sequential(\n",
    "            nn.Linear(d, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 2),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.arch1(x)\n",
    "        return out\n",
    "    \n",
    "model_MICE = MICENN()\n",
    "train_data = TensorDataset(Z_MICE_train, Y_train)\n",
    "train_loader = DataLoader(dataset = train_data, batch_size=20, shuffle=True)\n",
    "\n",
    "optimizer = optim.SGD(model_MICE.parameters(), lr=lr)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    for x_batch, y_batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        pred = model_MICE(x_batch)\n",
    "        loss = loss_fn(pred, y_batch)\n",
    "\n",
    "        # L1 penalty\n",
    "        l1_penalty = 0\n",
    "        for param in model_MICE.parameters():\n",
    "            l1_penalty += torch.sum(torch.abs(param))\n",
    "        # Add L1 penalty to the loss\n",
    "        loss += l1_lambda * l1_penalty\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    if epoch % 10 == 9:\n",
    "        print(f'Epoch {epoch}, Loss: {loss.item()}')\n",
    "\n",
    "_, labels = torch.max(model_MICE(Z_MICE_test), dim=1)\n",
    "pred = labels.detach().numpy()\n",
    "ER_MICE = np.mean(np.abs(pred - Y_test))\n",
    "print(ER_MICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
