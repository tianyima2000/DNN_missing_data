{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "# from missforest import MissForest\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 2*10**4\n",
    "d = 10\n",
    "\n",
    "lr = 0.01\n",
    "l1_lambda = 0 #0.001\n",
    "epochs = 100\n",
    "\n",
    "def reg_func(x):\n",
    "    y = 2 * (x[1] + 0.5)**(1/3) + np.exp((x[2] + x[3] + 1)/2) + 4 * x[3]**2    # Bayes risk approx 0.2290\n",
    "    # y = 2 * (x[1] + 0.5)**(1/3) + np.exp((x[2] + x[3] + 1)/2) + (4 * x[3])**2    # Bayes risk approx 0.9025\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.random.uniform(-0.5 , 0.5, (n, d))\n",
    "epsilon = np.random.normal(0, 0.25, n)\n",
    "Y = np.zeros(n)\n",
    "Y_true = np.zeros(n)\n",
    "for i in range(n):\n",
    "    Y_true[i] = reg_func(X[i,:])\n",
    "    Y[i] = Y_true[i] + epsilon[i]\n",
    "\n",
    "Omega = np.random.binomial(1, 0.5, (n, d))\n",
    "sample_mean = np.sum(X*Omega, axis = 0) / np.sum(Omega, axis = 0)\n",
    "Z_ZI = X * Omega\n",
    "\n",
    "Z_ZI_train = Z_ZI[0:int(n/2), :]\n",
    "Z_ZI_val = Z_ZI[int(n/2):int(3*n/4), :]\n",
    "Z_ZI_test = Z_ZI[int(3*n/4):n, :]\n",
    "Omega_train = Omega[0:int(n/2), :]\n",
    "Omega_val = Omega[int(n/2):int(3*n/4), :]\n",
    "Omega_test = Omega[int(3*n/4):n, :]\n",
    "\n",
    "Y_train = Y[0:int(n/2)]\n",
    "Y_val = Y[int(n/2):int(3*n/4)]\n",
    "Y_test = Y[int(3*n/4):n]\n",
    "Y_true_test = Y_true[int(3*n/4):n]\n",
    "\n",
    "Z_ZI_train = torch.tensor(Z_ZI_train, dtype=torch.float32)\n",
    "Z_ZI_val = torch.tensor(Z_ZI_val, dtype=torch.float32)\n",
    "Z_ZI_test = torch.tensor(Z_ZI_test, dtype=torch.float32)\n",
    "Omega_train = torch.tensor(Omega_train, dtype=torch.float32)\n",
    "Omega_val = torch.tensor(Omega_val, dtype=torch.float32)\n",
    "Omega_test = torch.tensor(Omega_test, dtype=torch.float32)\n",
    "\n",
    "Y_train = torch.tensor(Y_train.reshape(-1, 1), dtype=torch.float32)\n",
    "Y_val = torch.tensor(Y_val.reshape(-1, 1), dtype=torch.float32)\n",
    "Y_test = torch.tensor(Y_test.reshape(-1, 1), dtype=torch.float32)\n",
    "Y_true_test = torch.tensor(Y_true_test.reshape(-1, 1), dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, train_loss: 0.10958679020404816, val_loss: 0.2893974483013153\n",
      "Epoch 20, train_loss: 0.2710653245449066, val_loss: 0.28292107582092285\n",
      "Epoch 30, train_loss: 0.21033737063407898, val_loss: 0.2724165916442871\n",
      "Epoch 40, train_loss: 0.1927618831396103, val_loss: 0.2961089015007019\n",
      "Epoch 50, train_loss: 0.17029690742492676, val_loss: 0.264447420835495\n",
      "Epoch 60, train_loss: 0.1827601194381714, val_loss: 0.2651694416999817\n",
      "Epoch 70, train_loss: 0.2090921401977539, val_loss: 0.2648721933364868\n",
      "Epoch 80, train_loss: 0.31953901052474976, val_loss: 0.265537828207016\n",
      "Epoch 90, train_loss: 0.21863345801830292, val_loss: 0.266249418258667\n",
      "Epoch 100, train_loss: 0.14093215763568878, val_loss: 0.2672097086906433\n",
      "test_loss: 0.25075796246528625\n"
     ]
    }
   ],
   "source": [
    "### Pattern Embedding Neural Network (PENN)\n",
    "class PENN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        f2_output_dim = 8\n",
    "        embedding_dim = 2\n",
    "        \n",
    "        # Construct the neural network f2\n",
    "        self.f2 = nn.Sequential(\n",
    "            nn.Linear(d, 50),  \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50, 50),  \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50, 50),  \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50, f2_output_dim)\n",
    "        )\n",
    "\n",
    "        # Construct the neural network f3, i.e. the embedding function\n",
    "        self.f3 = nn.Sequential(\n",
    "            nn.Linear(d, 30),  \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(30, 30),  \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(30, 30),  \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(30, embedding_dim)\n",
    "        )\n",
    "\n",
    "        \n",
    "        # Construct the neural network f1\n",
    "        self.f1 = nn.Sequential(\n",
    "            nn.Linear(f2_output_dim + embedding_dim, 30),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(30, 30),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(30, 30),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(30, 1)  \n",
    "        )\n",
    "    \n",
    "    # Combine f1, f2 and f3 to construct the Pattern Embedding Neural Network (PENN)\n",
    "    def forward(self, z, omega):\n",
    "        # compute the output of f2 and f3\n",
    "        f2_output = self.f2(z)\n",
    "        f3_output = self.f3(omega)\n",
    "        \n",
    "        # Concatenate the output of f2 and f3\n",
    "        combined_features = torch.cat((f2_output, f3_output), dim=1)\n",
    "        \n",
    "        # Apply the combined network\n",
    "        final_output = self.f1(combined_features)\n",
    "        \n",
    "        return final_output\n",
    "    \n",
    "model_PENN = PENN()\n",
    "PENN_train_data = TensorDataset(Z_ZI_train, Omega_train, Y_train)\n",
    "PENN_train_loader = DataLoader(dataset = PENN_train_data, batch_size=20, shuffle=True)\n",
    "\n",
    "optimizer = optim.SGD(model_PENN.parameters(), lr=lr)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    for z_batch, omega_batch, y_batch in PENN_train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        pred = model_PENN(z_batch, omega_batch)\n",
    "        loss = loss_fn(pred, y_batch)\n",
    "\n",
    "        # L1 penalty\n",
    "        l1_penalty = 0\n",
    "        for param in model_PENN.parameters():\n",
    "            l1_penalty += torch.sum(torch.abs(param))\n",
    "        # Add L1 penalty to the loss\n",
    "        loss += l1_lambda * l1_penalty\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    model_PENN.eval()\n",
    "    val_loss = loss_fn(model_PENN(Z_ZI_val, Omega_val), Y_val)\n",
    "\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f'Epoch {epoch+1}, train_loss: {loss.item()}, val_loss: {val_loss}')\n",
    "\n",
    "print(f'test_loss: {loss_fn(model_PENN(Z_ZI_test, Omega_test), Y_test) - 0.2290}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, train_loss: 0.41881242394447327, val_loss: 0.29276207089424133\n",
      "Epoch 20, train_loss: 0.2133830338716507, val_loss: 0.28179872035980225\n",
      "Epoch 30, train_loss: 0.31873372197151184, val_loss: 0.29176002740859985\n",
      "Epoch 40, train_loss: 0.24851226806640625, val_loss: 0.29104724526405334\n",
      "Epoch 50, train_loss: 0.26487264037132263, val_loss: 0.28024712204933167\n",
      "Epoch 60, train_loss: 0.2127685844898224, val_loss: 0.2841445207595825\n",
      "Epoch 70, train_loss: 0.2593303918838501, val_loss: 0.2784324288368225\n",
      "Epoch 80, train_loss: 0.10762915760278702, val_loss: 0.2845163643360138\n",
      "Epoch 90, train_loss: 0.17687493562698364, val_loss: 0.28605684638023376\n",
      "Epoch 100, train_loss: 0.3109777271747589, val_loss: 0.28108516335487366\n",
      "test_loss: 0.04041251540184021\n"
     ]
    }
   ],
   "source": [
    "### Zero Imputation\n",
    "class NN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.nn = nn.Sequential(\n",
    "            nn.Linear(d, 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50, 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50, 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50, 30),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(30, 30),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(30, 30),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(30, 1)  \n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        final_output = self.nn(x)\n",
    "        return final_output\n",
    "    \n",
    "model_NN = NN()\n",
    "ZI_train_data = TensorDataset(Z_ZI_train, Y_train)\n",
    "ZI_train_loader = DataLoader(dataset = ZI_train_data, batch_size=20, shuffle=True)\n",
    "\n",
    "optimizer = optim.SGD(model_NN.parameters(), lr=lr)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    for z_batch, y_batch in ZI_train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        pred = model_NN(z_batch)\n",
    "        loss = loss_fn(pred, y_batch)\n",
    "\n",
    "        # L1 penalty\n",
    "        l1_penalty = 0\n",
    "        for param in model_NN.parameters():\n",
    "            l1_penalty += torch.sum(torch.abs(param))\n",
    "        # Add L1 penalty to the loss\n",
    "        loss += l1_lambda * l1_penalty\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    model_NN.eval()\n",
    "    val_loss = loss_fn(model_NN(Z_ZI_val), Y_val)\n",
    "\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f'Epoch {epoch+1}, train_loss: {loss.item()}, val_loss: {val_loss}')\n",
    "\n",
    "print(f'test_loss: {loss_fn(model_NN(Z_ZI_test), Y_test) - 0.2290}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
