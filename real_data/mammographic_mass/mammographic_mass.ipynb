{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from missforest import MissForest\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'uci_id': 161, 'name': 'Mammographic Mass', 'repository_url': 'https://archive.ics.uci.edu/dataset/161/mammographic+mass', 'data_url': 'https://archive.ics.uci.edu/static/public/161/data.csv', 'abstract': \"Discrimination of benign and malignant mammographic masses based on BI-RADS attributes and the patient's age.\", 'area': 'Health and Medicine', 'tasks': ['Classification'], 'characteristics': ['Multivariate'], 'num_instances': 961, 'num_features': 5, 'feature_types': ['Integer'], 'demographics': ['Age'], 'target_col': ['Severity'], 'index_col': None, 'has_missing_values': 'yes', 'missing_values_symbol': 'NaN', 'year_of_dataset_creation': 2007, 'last_updated': 'Thu Mar 28 2024', 'dataset_doi': '10.24432/C53K6Z', 'creators': ['Matthias Elter'], 'intro_paper': {'ID': 448, 'type': 'NATIVE', 'title': 'The prediction of breast cancer biopsy outcomes using two CAD approaches that both emphasize an intelligible decision process.', 'authors': 'M. Elter, R. Schulz-Wendtland, T. Wittenberg', 'venue': 'Medical Physics (Lancaster)', 'year': 2007, 'journal': None, 'DOI': None, 'URL': 'https://www.semanticscholar.org/paper/The-prediction-of-breast-cancer-biopsy-outcomes-two-Elter-Schulz-Wendtland/48666ddd437ca7bda95899d2ed1d0ae1ad58c9d0', 'sha': None, 'corpus': None, 'arxiv': None, 'mag': None, 'acl': None, 'pmid': None, 'pmcid': None}, 'additional_info': {'summary': \"Mammography is the most effective method for breast cancer screening\\r\\navailable today. However, the low positive predictive value of breast\\r\\nbiopsy resulting from mammogram interpretation leads to approximately\\r\\n70% unnecessary biopsies with benign outcomes. To reduce the high\\r\\nnumber of unnecessary breast biopsies, several computer-aided diagnosis\\r\\n(CAD) systems have been proposed in the last years.These systems\\r\\nhelp physicians in their decision to perform a breast biopsy on a suspicious\\r\\nlesion seen in a mammogram or to perform a short term follow-up\\r\\nexamination instead.\\r\\nThis data set can be used to predict the severity (benign or malignant)\\r\\nof a mammographic mass lesion from BI-RADS attributes and the patient's age.\\r\\nIt contains a BI-RADS assessment, the patient's age and three BI-RADS attributes\\r\\ntogether with the ground truth (the severity field) for 516 benign and\\r\\n445 malignant masses that have been identified on full field digital mammograms\\r\\ncollected at the Institute of Radiology of the\\r\\nUniversity Erlangen-Nuremberg between 2003 and 2006.\\r\\nEach instance has an associated BI-RADS assessment ranging from 1 (definitely benign)\\r\\nto 5 (highly suggestive of malignancy) assigned in a double-review process by\\r\\nphysicians. Assuming that all cases with BI-RADS assessments greater or equal\\r\\na given value (varying from 1 to 5), are malignant and the other cases benign,\\r\\nsensitivities and associated specificities can be calculated. These can be an\\r\\nindication of how well a CAD system performs compared to the radiologists.\\r\\n\\r\\nClass Distribution: benign: 516; malignant: 445\\r\\n\", 'purpose': None, 'funded_by': None, 'instances_represent': None, 'recommended_data_splits': None, 'sensitive_data': None, 'preprocessing_description': None, 'variable_info': \"6 Attributes in total (1 goal field, 1 non-predictive, 4 predictive attributes)\\r\\n\\r\\n1. BI-RADS assessment: 1 to 5 (ordinal, non-predictive!)  \\r\\n2. Age: patient's age in years (integer)\\r\\n3. Shape: mass shape: round=1 oval=2 lobular=3 irregular=4 (nominal)\\r\\n4. Margin: mass margin: circumscribed=1 microlobulated=2 obscured=3 ill-defined=4 spiculated=5 (nominal)\\r\\n5. Density: mass density high=1 iso=2 low=3 fat-containing=4 (ordinal)\\r\\n6. Severity: benign=0 or malignant=1 (binominal, goal field!)\\r\\n\\r\\n\\r\\nMissing Attribute Values:\\r\\n    - BI-RADS assessment:    2\\r\\n    - Age:                   5\\r\\n    - Shape:                31\\r\\n    - Margin:               48\\r\\n    - Density:              76\\r\\n    - Severity:              0\\r\\n\", 'citation': None}}\n",
      "       name     role     type demographic description units missing_values\n",
      "0   BI-RADS  Feature  Integer        None        None  None            yes\n",
      "1       Age  Feature  Integer         Age        None  None            yes\n",
      "2     Shape  Feature  Integer        None        None  None            yes\n",
      "3    Margin  Feature  Integer        None        None  None            yes\n",
      "4   Density  Feature  Integer        None        None  None            yes\n",
      "5  Severity   Target   Binary        None        None  None             no\n",
      "(961, 5)\n"
     ]
    }
   ],
   "source": [
    "from ucimlrepo import fetch_ucirepo \n",
    "  \n",
    "# fetch dataset \n",
    "mammographic_mass = fetch_ucirepo(id=161) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = mammographic_mass.data.features \n",
    "Y = mammographic_mass.data.targets \n",
    "  \n",
    "# metadata \n",
    "print(mammographic_mass.metadata) \n",
    "  \n",
    "# variable information \n",
    "print(mammographic_mass.variables) \n",
    "\n",
    "print(X.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "Omega = X.isna().to_numpy()\n",
    "Omega = Omega.astype(int)\n",
    "\n",
    "X_ZI = X.fillna(0)\n",
    "X_ZI = X_ZI.to_numpy()\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_ZI)\n",
    "X_ZI = scaler.transform(X_ZI)\n",
    "\n",
    "sample_mean = X.mean()\n",
    "X_MI = X.fillna(sample_mean)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_MI)\n",
    "X_MI = scaler.transform(X_MI)\n",
    "\n",
    "Y = Y.to_numpy().reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ZI_train, X_ZI_test, X_MI_train, X_MI_test, Y_train, Y_test, Omega_train, Omega_test = train_test_split(X_ZI, X_MI, Y, Omega, test_size=161, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ZI_train = torch.tensor(X_ZI_train, dtype=torch.float32)\n",
    "X_ZI_test = torch.tensor(X_ZI_test, dtype=torch.float32)\n",
    "\n",
    "X_MI_train = torch.tensor(X_MI_train, dtype=torch.float32)\n",
    "X_MI_test = torch.tensor(X_MI_test, dtype=torch.float32)\n",
    "\n",
    "Omega_train = torch.tensor(Omega_train, dtype=torch.float32)\n",
    "Omega_test = torch.tensor(Omega_test, dtype=torch.float32)\n",
    "\n",
    "Y_train = torch.tensor(Y_train, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Loss: 0.5106790065765381\n",
      "Epoch 19, Loss: 0.3638306260108948\n",
      "Epoch 29, Loss: 0.3738839626312256\n",
      "Epoch 39, Loss: 0.2965232729911804\n",
      "Epoch 49, Loss: 0.31402263045310974\n",
      "Epoch 59, Loss: 0.3274551331996918\n",
      "Epoch 69, Loss: 0.4839431941509247\n",
      "Epoch 79, Loss: 0.397629976272583\n",
      "Epoch 89, Loss: 0.48749831318855286\n",
      "Epoch 99, Loss: 0.29553094506263733\n",
      "Epoch 109, Loss: 0.6002846360206604\n",
      "Epoch 119, Loss: 0.3556693494319916\n",
      "Epoch 129, Loss: 0.355730801820755\n",
      "Epoch 139, Loss: 0.3913477063179016\n",
      "Epoch 149, Loss: 0.4459676742553711\n",
      "Epoch 159, Loss: 0.3971387445926666\n",
      "Epoch 169, Loss: 0.4150277078151703\n",
      "Epoch 179, Loss: 0.37465810775756836\n",
      "Epoch 189, Loss: 0.29482516646385193\n",
      "Epoch 199, Loss: 0.6196262240409851\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(0.16770186335403728)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 0.001\n",
    "epochs = 200\n",
    "l1_lambda = 0\n",
    "\n",
    "class TwoStreamModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        embedding_dim = 2\n",
    "        \n",
    "        # The embedding layer\n",
    "        self.embedding = nn.Sequential(\n",
    "            nn.Linear(5, 2),  \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(2, embedding_dim),  \n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # Combined network for the layers after embedding\n",
    "        self.combined = nn.Sequential(\n",
    "            nn.Linear(5 + embedding_dim, 5),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(5, 5),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(5, 5),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(5, 5),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(5, 2)  # Output layer\n",
    "        )\n",
    "    \n",
    "    def forward(self, x, omega):\n",
    "        # Apply the embedding layer to omega\n",
    "        embedded = self.embedding(omega)\n",
    "        \n",
    "        # Concatenate the embedding with x\n",
    "        combined_features = torch.cat((x, embedded), dim=1)\n",
    "        \n",
    "        # Apply the combined network\n",
    "        final_out = self.combined(combined_features)\n",
    "        \n",
    "        return final_out\n",
    "    \n",
    "\n",
    "model_PE = TwoStreamModel()\n",
    "PE_train_data = TensorDataset(X_ZI_train, Omega_train, Y_train)\n",
    "PE_train_loader = DataLoader(dataset = PE_train_data, batch_size=32, shuffle=True)\n",
    "\n",
    "optimizer = optim.Adam(model_PE.parameters(), lr=lr)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)\n",
    "loss_fn = nn.CrossEntropyLoss()   \n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    for x_batch, omega_batch, y_batch in PE_train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        pred = model_PE(x_batch, omega_batch)\n",
    "        loss = loss_fn(pred, y_batch)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    if epoch % 10 == 9:\n",
    "        print(f'Epoch {epoch}, Loss: {loss.item()}')\n",
    "\n",
    "_, labels = torch.max(model_PE(X_ZI_test, Omega_test), dim=1)\n",
    "pred = labels.detach().numpy()\n",
    "np.mean(np.abs(pred - Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Loss: 0.6302314400672913\n",
      "Epoch 19, Loss: 0.49396929144859314\n",
      "Epoch 29, Loss: 0.5680058598518372\n",
      "Epoch 39, Loss: 0.4505730867385864\n",
      "Epoch 49, Loss: 0.457862913608551\n",
      "Epoch 59, Loss: 0.4324200451374054\n",
      "Epoch 69, Loss: 0.45647433400154114\n",
      "Epoch 79, Loss: 0.5443997383117676\n",
      "Epoch 89, Loss: 0.5014747977256775\n",
      "Epoch 99, Loss: 0.37881484627723694\n",
      "Epoch 109, Loss: 0.49651721119880676\n",
      "Epoch 119, Loss: 0.4855366349220276\n",
      "Epoch 129, Loss: 0.4757787883281708\n",
      "Epoch 139, Loss: 0.5127899050712585\n",
      "Epoch 149, Loss: 0.4404394030570984\n",
      "Epoch 159, Loss: 0.6043076515197754\n",
      "Epoch 169, Loss: 0.37158384919166565\n",
      "Epoch 179, Loss: 0.377371609210968\n",
      "Epoch 189, Loss: 0.38464754819869995\n",
      "Epoch 199, Loss: 0.5572265386581421\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(0.17391304347826086)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 0.001\n",
    "epochs = 200\n",
    "l1_lambda = 0\n",
    "\n",
    "class FCModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(5, 5),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(5, 5),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(5, 5),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(5, 5),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(5, 2)  # Output layer\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):   \n",
    "        final_out = self.fc(x)\n",
    "        return final_out\n",
    "    \n",
    "\n",
    "model_MI = FCModel()\n",
    "MI_train_data = TensorDataset(X_MI_train, Y_train)\n",
    "MI_train_loader = DataLoader(dataset = MI_train_data, batch_size=32, shuffle=True)\n",
    "\n",
    "optimizer = optim.Adam(model_MI.parameters(), lr=lr)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)\n",
    "loss_fn = nn.CrossEntropyLoss()   \n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    for x_batch, y_batch in MI_train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        pred = model_MI(x_batch)\n",
    "        loss = loss_fn(pred, y_batch)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    if epoch % 10 == 9:\n",
    "        print(f'Epoch {epoch}, Loss: {loss.item()}')\n",
    "\n",
    "_, labels = torch.max(model_MI(X_MI_test), dim=1)\n",
    "pred = labels.detach().numpy()\n",
    "np.mean(np.abs(pred - Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
